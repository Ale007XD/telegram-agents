import httpx
import logging
import asyncio
import json

class BaseAgent:
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.url = "https://openrouter.ai/api/v1/chat/completions"
        
        # –¶–µ–ø–æ—á–∫–∞ –ë–ï–°–ü–õ–ê–¢–ù–´–• –º–æ–¥–µ–ª–µ–π (–æ—Ç —Å–∞–º–æ–π —É–º–Ω–æ–π –∫ —Å–∞–º–æ–π –ø—Ä–æ—Å—Ç–æ–π)
        self.fallback_chain = [
            "meta-llama/llama-3.3-70b-instruct:free",   # –£–º–Ω–∞—è (Smartest)
            "mistralai/mistral-nemo:free",              # –°—Ç–∞–±–∏–ª—å–Ω–∞—è (Stable)
            "google/gemma-2-9b-it:free",                # –†–µ–∑–µ—Ä–≤ 1
            "microsoft/phi-3-medium-128k-instruct:free" # –†–µ–∑–µ—Ä–≤ 2
        ]

    async def _call(self, model: str, messages: list, attempt: int = 0) -> str:
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            "HTTP-Referer": "https://github.com/skillsllm/bot",
            "X-Title": "SkillsLLM Bot"
        }
        
        payload = {
            "model": model,
            "messages": messages,
            "temperature": 0.7,
            "max_tokens": 1500
        }

        async with httpx.AsyncClient(timeout=60.0) as client:
            try:
                logging.info(f"üß† Trying AI model: {model}...")
                response = await client.post(self.url, json=payload, headers=headers)
                
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ API
                if response.status_code in [404, 429, 500, 502, 503]:
                    logging.warning(f"‚ö†Ô∏è Model {model} unavailable (Status: {response.status_code})")
                    raise ValueError("Model unavailable")
                
                response.raise_for_status()
                data = response.json()
                
                if 'choices' in data and len(data['choices']) > 0:
                    return data['choices'][0]['message']['content']
                else:
                    raise ValueError(f"Empty response: {data}")

            except Exception as e:
                # –õ–æ–≥–∏–∫–∞ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è (Fallback)
                next_attempt = attempt + 1
                if next_attempt < len(self.fallback_chain):
                    next_model = self.fallback_chain[next_attempt]
                    logging.info(f"üîÑ Switching to fallback model: {next_model}")
                    return await self._call(next_model, messages, next_attempt)
                
                logging.error(f"‚ùå All AI models failed. Last error: {e}")
                return "üòî –ò–∑–≤–∏–Ω–∏—Ç–µ, –≤—Å–µ AI-—Å–µ—Ä–≤–∏—Å—ã —Å–µ–π—á–∞—Å –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω—ã. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —á–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É."

class Planner(BaseAgent):
    async def process(self, task: str, history: list) -> str:
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏—Å—Ç–æ—Ä–∏–∏
        valid_history = [m for m in history if isinstance(m, dict) and m.get('content')]
        
        system_msg = {
            "role": "system", 
            "content": "–¢—ã –æ–ø—ã—Ç–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –¢–≤–æ—è —Ü–µ–ª—å - –ø–æ–º–æ—á—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é, —Å–æ—Å—Ç–∞–≤–∏–≤ —á–µ—Ç–∫–∏–π –ø–ª–∞–Ω –∏–ª–∏ –¥–∞–≤ —Ç–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç. –ò—Å–ø–æ–ª—å–∑—É–π Markdown."
        }
        
        messages = [system_msg] + valid_history + [{"role": "user", "content": task}]
        return await self._call(self.fallback_chain[0], messages)

class Verifier(BaseAgent):
    async def process(self, text: str) -> str:
        messages = [
            {"role": "system", "content": "–¢—ã –∫—Ä–∏—Ç–∏–∫. –ü—Ä–æ–≤–µ—Ä—å —Ç–µ–∫—Å—Ç –Ω–∞ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∏ –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏. –ï—Å–ª–∏ –≤—Å–µ —Ö–æ—Ä–æ—à–æ - –Ω–∞–ø–∏—à–∏ '–û—à–∏–±–æ–∫ –Ω–µ—Ç'."},
            {"role": "user", "content": f"–¢–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏:\n{text}"}
        ]
        return await self._call(self.fallback_chain[0], messages)
